{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wavenet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hamed1337/Virtual-Assistant/blob/master/wavenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPlc7Y42U4n2",
        "colab_type": "text"
      },
      "source": [
        "#Imports and constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8lV_aZY0bei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorflow2 = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGKAJokKHciu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if tensorflow2:\n",
        "  !pip uninstall keras\n",
        "  !pip uninstall tensorflow\n",
        "  !pip install tensorflow-gpu==2.0.0-alpha0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmtQLxJWfJKz",
        "colab_type": "code",
        "outputId": "a43f6d51-f666-491d-91b2-2540fdf2e96f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "#import utils\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import backend as K\n",
        "# from tensorflow.keras.backend import manual_variable_initialization\n",
        "# manual_variable_initialization(False)\n",
        "\n",
        "from IPython.core.debugger import Tracer\n",
        "import time\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import pickle \n",
        "\n",
        "from tensorflow.keras.layers import Conv1D, BatchNormalization, Lambda, concatenate, Flatten, Input, Dense\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from tensorflow.python.saved_model import builder as saved_model_builder\n",
        "from tensorflow.python.saved_model import signature_constants, tag_constants\n",
        "from tensorflow.python.saved_model.signature_def_utils_impl import predict_signature_def\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import gc\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y4993c6YtTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from tensorflow.python.client import device_lib\n",
        "\n",
        "# device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alI0X9mifJK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "input_dimension = 20 #MUST BE CHANGED TO MATCH MFCC COEFFICIENTS DIMENSION\n",
        "num_dim = 128      # latent dimension\n",
        "num_blocks = 3\n",
        "output_dimension = 29\n",
        "epochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_8WMCYMJZZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root_path = '/content/drive/My Drive/Data/VoiceData/'\n",
        "model_path = '/content/drive/My Drive/Data/'\n",
        "libri_path = root_path + 'Libri/'\n",
        "ted_path = root_path + 'Tedlium/'\n",
        "vctk_path = root_path + 'Vctk/'\n",
        "number_of_files = 3\n",
        "data_paths = [vctk_path, ted_path, libri_path]\n",
        "genders = ['m', 'f']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VQXLijgZkDt",
        "colab_type": "text"
      },
      "source": [
        "#Reading the data (this section should be in a separate .py file)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DZGRBPzH0VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def combine_files(files):\n",
        "  return np.concatenate([np.load(file, allow_pickle = True) for file in files])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxzCTz_3VLkk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#returns the inputs length\n",
        "def get_input_length_numpy(inputs):\n",
        "    return [np.count_nonzero(_input.sum(axis = -1), axis = -1) for _input in inputs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbg7KJ_yn9mZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_data(l, padding_value = 0):\n",
        "  return [pad_sequences(l[i : i +  batch_size], padding = 'post', value = padding_value) for i in range(0, len(l), batch_size)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xqo0-WovuFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def expand_labels(batch_labels):\n",
        "   return [np.expand_dims(item, axis = -1) for item in batch_labels]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY0vyt4bkg5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data(mfccs_paths, labels_paths):\n",
        "  mfcc_np = combine_files(mfccs_paths)\n",
        "  label_np = combine_files(labels_paths)\n",
        "  print(mfcc_np.shape)\n",
        "  print(label_np.shape)\n",
        "  return train_test_split(mfcc_np, label_np, test_size = 0.05, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ol-yVnzKbY6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(mfccs_paths, labels_paths):\n",
        "  data = read_data(mfccs_paths, labels_paths)\n",
        "  \n",
        "  padding_values = [0, 0, -1, -1]\n",
        "  \n",
        "  data_batches = [batch_data(data[i], padding_values[i]) for i in range(len(data))]\n",
        "      \n",
        "  X_train_batches, X_test_batches, Y_train_batches, Y_test_batches = tuple(data_batches)\n",
        "  \n",
        "  input_length_train = get_input_length_numpy(X_train_batches)\n",
        "  input_length_test = get_input_length_numpy(X_test_batches)\n",
        "  \n",
        "  Y_train_batches = expand_labels(Y_train_batches)\n",
        "  Y_test_batches = expand_labels(Y_test_batches)\n",
        "  \n",
        "  return X_train_batches, Y_train_batches, input_length_train, X_test_batches, Y_test_batches, input_length_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKQtTDsxOEUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_data():\n",
        "  \n",
        "  import itertools\n",
        "  \n",
        "  mfccs_paths = [[path + 'mfccs_' + gender + '_' + str(i) + '.npy'  for gender, path in itertools.product(genders, data_paths)] for i in range(number_of_files)]\n",
        "  labels_paths =  [[path + 'labels_' + gender + '_' + str(i) + '.npy'  for gender, path in itertools.product(genders, data_paths)] for i in range(number_of_files)]\n",
        "  \n",
        "  all_data = [np.asarray([]) for i in range(6)]\n",
        "  \n",
        "  for mfccs, labels in zip(mfccs_paths, labels_paths):\n",
        "    data = get_data(mfccs, labels)\n",
        "    for i in range(len(data)):\n",
        "      all_data[i] = np.concatenate((all_data[i], data[i]))\n",
        "      \n",
        "  return tuple(all_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vG2SKeHAmgt",
        "colab_type": "code",
        "outputId": "16e088ce-2fa9-4486-fbc8-4744d05fa01c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "X_train_batches, Y_train_batches, input_length_train, X_test_batches, Y_test_batches, input_length_test = get_all_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(66784,)\n",
            "(66784,)\n",
            "(66784,)\n",
            "(66784,)\n",
            "(66777,)\n",
            "(66777,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZF5XUqqHbAO",
        "colab_type": "code",
        "outputId": "47db76fd-ceb5-410b-f187-983b4b5a9a6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Y_train_batches.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11897,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTxT7UTXr3Uv",
        "colab_type": "code",
        "outputId": "3dc5aad5-654e-4333-9cf8-33d1633d81cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv81usTAU17w",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEbWYJizfJK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def res_block(tensor, size, rate, block, dim = num_dim):\n",
        "\n",
        "    # filter convolution\n",
        "    conv_filter = Conv1D(num_dim, size, activation='tanh', dilation_rate = rate, padding = 'causal')(tensor)\n",
        "    conv_filter = BatchNormalization()(conv_filter)\n",
        "\n",
        "    # gate convolution\n",
        "    conv_gate = Conv1D(num_dim, size, activation = 'sigmoid', dilation_rate = rate, padding = 'causal')(tensor)\n",
        "    conv_gate = BatchNormalization()(conv_gate)\n",
        "\n",
        "    # output by gate multiplying\n",
        "    out = keras.layers.multiply([conv_filter,conv_gate])\n",
        "\n",
        "    # final output\n",
        "    out = Conv1D(num_dim, 1, activation='tanh', padding='same')(out)\n",
        "    out = BatchNormalization()(out)\n",
        "\n",
        "    # residual and skip output\n",
        "    return keras.layers.add([out, tensor]), out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkY0vf2RfJK8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  \n",
        "  tf.reset_default_graph()\n",
        "  sess = tf.Session()\n",
        "  K.set_session(sess)\n",
        "   \n",
        "  inputs = Input(shape = (None, input_dimension,), name = 'inputs')\n",
        "  z = Conv1D(num_dim, 1, activation = 'tanh', padding = 'same')(inputs)\n",
        "\n",
        "  skip = []\n",
        "  for i in range(num_blocks):\n",
        "      for r in [1, 2, 4, 8, 16]:\n",
        "          z, s = res_block(z, size = 7, rate = r, block = i)\n",
        "          skip.append(s)\n",
        "\n",
        "  skip = keras.layers.add(skip)\n",
        "  \n",
        "  logit = Conv1D(num_dim, 1, activation = 'tanh', padding = 'same')(skip)\n",
        "  logit = BatchNormalization()(logit)\n",
        "\n",
        "  logit = Conv1D(output_dimension, 1, padding = 'same', activation = 'linear')(logit)\n",
        "  \n",
        "  return inputs, logit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDLi09yz8lTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_input_length(inputs):\n",
        "  return tf.reduce_sum(tf.cast(tf.not_equal(tf.reduce_sum(inputs, axis = -1), 0.), 'int32'), axis = -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi_AcoeTj5V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tensor_lengths(tensor, padding_value):\n",
        "  return tf.cast(tf.reduce_sum(tf.cast(tf.not_equal(tensor, padding_value), 'int32'), axis = -1), 'float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiXBir7ijRZg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ctc_decoder(args):\n",
        "  input_length, logits = args\n",
        "  logits = tf.transpose(logits, perm = [1, 0, 2])\n",
        "  decoded_sequences, _ = tf.nn.ctc_greedy_decoder(logits, tf.cast(input_length, 'int32'))\n",
        "  decoded_sequences_dense = tf.sparse_to_dense(decoded_sequences[0].indices, decoded_sequences[0].dense_shape, decoded_sequences[0].values, default_value = -1)\n",
        "\n",
        "  return tf.cast(decoded_sequences_dense, 'float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE3csLeeWde2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tf_dense_to_sparse(dense, padding_value = 0):\n",
        "  padding = tf.constant(padding_value, dtype = tf.float32)\n",
        "  where = tf.not_equal(dense, padding)\n",
        "  indices = tf.where(where)\n",
        "  values = tf.gather_nd(dense, indices)\n",
        "  return tf.SparseTensor(indices, values, tf.cast(tf.shape(dense), 'int64'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kzukJvDhNS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def edit_distance_v2(y_true, y_pred):\n",
        "  \n",
        "  y_true_sparse = tf_dense_to_sparse(y_true, -1)\n",
        "  y_pred_sparse = tf_dense_to_sparse(y_pred, -1)\n",
        "  \n",
        "  edit_distance = tf.edit_distance(y_pred_sparse, y_true_sparse, normalize = False)\n",
        "  \n",
        "  y_true_lengths = get_tensor_lengths(y_true, -1)\n",
        "  y_pred_lengths = get_tensor_lengths(y_pred, -1)\n",
        "  \n",
        "  edit_distance = edit_distance / tf.maximum(y_true_lengths, y_pred_lengths)\n",
        "  \n",
        "  return 1.0 - tf.reduce_mean(edit_distance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPWR8g7zoQQ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _edit_distance_acc(input_length):\n",
        "  \n",
        "  def edit_distance_acc(y_true, y_pred):\n",
        "    \n",
        "    y_pred = ctc_decoder((input_length, y_pred))\n",
        "    y_true = tf.squeeze(y_true, axis = -1)\n",
        "    return edit_distance_v2(y_true, y_pred)\n",
        "  \n",
        "  return edit_distance_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtEwWTsrfJK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _ctc_loss(input_length):\n",
        "  \n",
        "  def ctc_loss(y_true ,y_pred):\n",
        "    y_true = tf.squeeze(y_true, axis = -1)\n",
        "    y_true = tf_dense_to_sparse(y_true, padding_value = -1)\n",
        "    return tf.nn.ctc_loss(tf.cast(y_true, 'int32'), y_pred, tf.cast(input_length, 'int32'), time_major = False)\n",
        "\n",
        "  return ctc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_eGgffKz4ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_model(inputs, logit):\n",
        "\n",
        "  input_length = Input(shape = (), name = 'input_length')\n",
        "  training_model = Model([inputs, input_length], [logit])\n",
        "  adam_optimizer = tf.keras.optimizers.Adam(lr = 0.0005)\n",
        "  training_model.compile(loss = _ctc_loss(input_length), metrics = [_edit_distance_acc(input_length)], optimizer = adam_optimizer)\n",
        "  \n",
        "  return training_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xgxKEb13jkR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_prediction_model(inputs, logit):\n",
        "    \n",
        "  input_length = Lambda(get_input_length)(inputs)\n",
        "  decoded_sequences = Lambda(ctc_decoder)([input_length, logit])\n",
        "  prediction_model = Model(inputs, decoded_sequences)\n",
        "  \n",
        "  return prediction_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFKUKc4opSNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_models():\n",
        "  inputs, logit = create_model()\n",
        "  training_model = get_training_model(inputs, logit)\n",
        "  prediction_model = get_prediction_model(inputs, logit)\n",
        "  \n",
        "  return training_model, prediction_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUzc4JU4pd8g",
        "colab_type": "code",
        "outputId": "4ecd2880-7caa-491f-cbde-ca4fab3116d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "source": [
        "training_model, prediction_model = get_models()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From <ipython-input-21-c0acfcdde096>:5: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgCNQkPGV06e",
        "colab_type": "text"
      },
      "source": [
        "#Load Model/Optimizer state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IQpyX7gVt6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model(model = training_model, path = model_path):\n",
        "  model.load_weights(path + 'weights.h5')\n",
        "  #loading optimizer state to retrieve running means used in trainning\n",
        "#   model._make_train_function()\n",
        "  with open(path + 'optimizer.pkl', 'rb') as f:\n",
        "      weight_values = pickle.load(f)\n",
        "  model.optimizer.set_weights(weight_values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1445TvuVcArh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  load_model()\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbweCxdyT3WV",
        "colab_type": "text"
      },
      "source": [
        "#Save Model/Optimizer state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSKTSZJgvIEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(model = training_model, path = model_path):\n",
        "  model.save_weights(path + 'weights.h5')\n",
        "  symbolic_weights = getattr(model.optimizer, 'weights')\n",
        "  weight_values = K.batch_get_value(symbolic_weights)\n",
        "  with open(path + 'optimizer.pkl', 'wb') as f:\n",
        "      pickle.dump(weight_values, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDk34PatoyUV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelSaver(keras.callbacks.Callback):\n",
        "  def __init__(self, filepath = model_path, period = 1):\n",
        "    self.period = period\n",
        "    self.filepath = filepath    \n",
        "    \n",
        "  def on_train_begin(self, logs = {}):\n",
        "      self.best_acc = float('-inf')\n",
        "      self.count = 0\n",
        "        \n",
        "  def on_epoch_end(self, batch, logs = {}):    \n",
        "    self.count += 1\n",
        "    current_acc = logs['val_edit_distance_acc']\n",
        "       \n",
        "    if(self.count % self.period == 0):\n",
        "      if(current_acc > self.best_acc):\n",
        "        print(\"epoch number: \", self.count, \"saved\")\n",
        "        self.best_acc = current_acc\n",
        "        save_model(path = self.filepath)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGjGJJ_JWFXF",
        "colab_type": "text"
      },
      "source": [
        "#Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_Jso1oOO99i",
        "colab_type": "code",
        "outputId": "f00c1280-d4cb-468d-a4a8-5f7f7ee119a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8MG97c-bnqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator(X_batches, Y_batches, input_length_batches):\n",
        "    while True:     \n",
        "        for X_batch, Y_batch, input_length_batch in zip(X_batches, Y_batches, input_length_batches):\n",
        "          yield ([X_batch,  input_length_batch], Y_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c70vnoEVWIuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training_model.fit([X_train_batches[273][16:17], input_length_batches[273][16:17], label_length_batches[273][16:17]], Y_train_batches[273][16:17], epochs = 5, batch_size = 1, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "83-w2e32K7lY",
        "outputId": "ed08c5a9-384a-440d-ea2e-63d14e43a64f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "training_model.fit_generator(generator(X_train_batches, Y_train_batches, input_length_train), \n",
        "                             steps_per_epoch = len(X_train_batches), epochs = epochs, callbacks = [ModelSaver(period = 2)],\n",
        "                             validation_data = generator(X_test_batches, Y_test_batches, input_length_test), validation_steps = len(X_test_batches), \n",
        "                             max_queue_size = 100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/20\n",
            " 4916/11897 [===========>..................] - ETA: 29:42 - loss: inf - edit_distance_acc: 0.7153"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzE05t3EMR3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.fit([tf_data, np.concatenate(input_length_batches), np.concatenate(label_length_batches)], tf_labels, epochs = 10, batch_size = 128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqhN223jcogL",
        "colab_type": "text"
      },
      "source": [
        "# Random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxgVarxfz3Bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_model.save('prediction_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti4-8gjA4W6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_audio_length = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gg2Fk3D0goZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converter = tf.lite.TFLiteConverter.from_keras_model_file(\"prediction_model.h5\", input_shapes = {\"inputs\" : [None, max_audio_length, input_dimension]})\n",
        "# converter = tf.lite.TFLiteConverter.from_keras_model(prediction_model)\n",
        "# tflite_model = converter.convert()\n",
        "# open(\"prediction_model.tflite\", \"wb\").write(tflite_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmYGi3c5MrH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #input is a list containing numpy arrays[samples], use none for dynamic padding. \n",
        "# def tf_padding(input_list, element_shape, batch_size):\n",
        "  \n",
        "#   def custom_generator():  \n",
        "#     while True:\n",
        "#         for item in input_list:\n",
        "#           yield item\n",
        "#         break\n",
        "        \n",
        "#   tf_data = tf.data.Dataset.from_generator(custom_generator, output_types = tf.float64)\n",
        "#   tf_data = tf_data.padded_batch(batch_size = batch_size, padded_shapes = element_shape)\n",
        "#   iterator = tf_data.make_one_shot_iterator()\n",
        "#   data = iterator.get_next()\n",
        "#   tf_batches = []\n",
        "\n",
        "#   with tf.Session() as sess:\n",
        "#     while True:\n",
        "#       try:\n",
        "#         tf_batches.append(sess.run(data))\n",
        "#       except tf.errors.OutOfRangeError:\n",
        "#         break\n",
        "        \n",
        "#   return tf_batches\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNz5dabBOsTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf_data = np.concatenate(tf_padding(X, tf.TensorShape([600, input_dimension]), 1))\n",
        "# tf_labels = np.expand_dims(np.concatenate(tf_padding(Y, tf.TensorShape([200]), 1)), axis = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvMbbkqyZkQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def edit_distance(arr1, arr2):\n",
        "  n = arr1.shape[0]\n",
        "  m = arr2.shape[0]\n",
        "  dp = np.zeros((n + 1, m + 1), dtype = int)\n",
        "  for i in range(n + 1):\n",
        "    for j in range(m + 1):\n",
        "      if i==0:\n",
        "        dp[i][j] = j\n",
        "      elif j==0:\n",
        "        dp[i][j] = i\n",
        "      elif arr1[i-1] == arr2[j - 1]:\n",
        "        dp[i][j] = dp[i - 1][j - 1]\n",
        "      else:\n",
        "        dp[i][j] = 1 + min(dp[i][j - 1], dp[i - 1][j], dp[i - 1][j - 1])\n",
        "  return  1 - dp[n][m] / max(n, m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvCnDnuTsdaL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index2byte = ['<EMP>', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
        "              'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q',\n",
        "              'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMdXaCS1sjBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def index2str(index_list):\n",
        "    # transform label index to character\n",
        "    str_ = ''\n",
        "    for ch in index_list:\n",
        "        if ch > 0:\n",
        "            str_ += index2byte[ch]\n",
        "        else:  # <EOS>\n",
        "            break\n",
        "    return str_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yxMGGCZwvXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_index(indices):\n",
        "    for index_list in indices:\n",
        "        print(index2str(index_list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVNy1Gtgskmj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_predictions():\n",
        "  for j in range(len(X_test_batches)):\n",
        "    for i in range(1, batch_size):\n",
        "      y_true = Y_test_batches[j][i - 1 : i]\n",
        "      x_test = X_test_batches[j][i - 1 : i]\n",
        "      input_length = input_length_test[j][i - 1 : i]\n",
        "      loss, metric = training_model.evaluate([x_test, input_length], y_true, batch_size = batch_size, verbose = 0)      \n",
        "      y_pred = prediction_model.predict(x_test, batch_size = batch_size).astype('int32')\n",
        "      print('ctc loss = %f, edit distance = %f' %(loss, metric))\n",
        "      print_index(np.squeeze(y_true, axis = -1))\n",
        "      print_index(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8lGLGa6IH6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print_predictions()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}