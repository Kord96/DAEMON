{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ol0vXp-Ijdds",
    "outputId": "f99cb6e2-9e6b-4a74-b7b4-6423c6ab9411"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import utils\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "from keras.layers import Dense\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "#import keras.layers.LSTM\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# mounr google drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "fmmMWIC3jfj3",
    "outputId": "535ddffe-b8af-41eb-ee5f-60b3555a5e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#loading glove\n",
    "#note: should be dumbed into drive to not download it everytime\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "EbjfQCpGj2vL",
    "outputId": "ef143d24-e965-42b0-defe-87ac5add996e"
   },
   "outputs": [],
   "source": [
    "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "#!unzip ngrok-stable-linux-amd64.zip\n",
    "\n",
    "# def tensorBoard():\n",
    "#   LOG_DIR = './log'\n",
    "#   get_ipython().system_raw(\n",
    "#     'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
    "#     .format(LOG_DIR)\n",
    "#    )\n",
    "#   get_ipython().system_raw('./ngrok http 6006 &')\n",
    "#   !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "#     \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
    "\n",
    "# #use this link to enter tensorBoard\n",
    "# tensorBoard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "8l7Sv4eGj5Sm",
    "outputId": "1511759d-112b-4bd6-a534-981f7a6ab968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6619\n",
      "6619\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "#Loading the data\n",
    "\n",
    "df = []\n",
    "all_labels=[]\n",
    "lengthes=[]\n",
    "\n",
    "#should add others class\n",
    "number_of_classes = 16\n",
    "\n",
    "for i in range(number_of_classes):\n",
    "    with open(path+str(i+1)+'.txt') as f:\n",
    "      contentTemp = f.readlines()\n",
    "      length = len(contentTemp)\n",
    "      tmp=np.empty(length)\n",
    "      tmp.fill(i)\n",
    "      all_labels.append(tmp)\n",
    "      df.append(contentTemp)\n",
    "      lengthes.append(length)\n",
    "      \n",
    " \n",
    "#flattening, probably better to use built in function\n",
    "df = [item for sublist in df for item in sublist]\n",
    "all_labels = [item for sublist in all_labels for item in sublist]\n",
    "print(len(df))\n",
    "print(len(all_labels))\n",
    "print(len(lengthes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "STQMu2yJZTUM",
    "outputId": "194bf0dc-f778-4930-d10a-f83f63c30346"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500, 184, 300, 200, 276, 296, 203, 592, 406, 296, 203, 296, 203, 16, 10, 2638]\n"
     ]
    }
   ],
   "source": [
    "#size of each class\n",
    "print(lengthes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NRPmmFWVj7bp"
   },
   "outputs": [],
   "source": [
    "max_length=20\n",
    "\n",
    "def get_encoded_sentences(X):\n",
    "    t = Tokenizer()\n",
    "    t.fit_on_texts(X)\n",
    "    encoded_sent=t.texts_to_sequences(X)\n",
    "    return pad_sequences(encoded_sent, maxlen=max_length, padding='post'),t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3ipYAZaaVZq"
   },
   "outputs": [],
   "source": [
    "for i,sentence in enumerate(df):\n",
    "    df[i] = sentence.replace(\"\\n\",\".\")\n",
    "\n",
    "#get encoded data\n",
    "encoded_df,t=get_encoded_sentences(df)\n",
    "\n",
    "vocab_size = len(t.word_index) + 1\n",
    "# create a weight matrix for words in training docs\n",
    "embedding_matrix = np.zeros((vocab_size, 100))\n",
    "for word, i in t.word_index.items():\n",
    "\tembedding_vector = embeddings_index.get(word)\n",
    "\tif embedding_vector is not None:\n",
    "\t\tembedding_matrix[i] = embedding_vector\n",
    "  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_df, all_labels, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "mFJA0bjAj7db",
    "outputId": "bf4bfda3-810e-428d-c0db-1da308115d60"
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_length, trainable=True))\n",
    "model.add(keras.layers.LSTM(100, return_sequences=False, dropout=0.5))\n",
    "model.add(Dense(number_of_classes, activation='softmax'))\n",
    "#model.add(keras.layers.TimeDistributed(Dense(vocab_size)))\n",
    "#model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "writer = tf.summary.Fil`eWriter('./log', graph=sess.graph)\n",
    "# fit the model\n",
    "# evaluate the model\n",
    "#sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, to_categorical(y_train), epochs=15)\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "9k6z2-KPj7mt",
    "outputId": "35c8a998-7704-489e-b9b1-f9e26502feb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2648/2648 [==============================] - 2s 783us/step\n",
      "test Accuracy: 99.962236\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, to_categorical(y_test))\n",
    "print('test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m8YK_34gD8oA"
   },
   "outputs": [],
   "source": [
    "def classify_sentence(sentence):\n",
    "    sequence = pad_sequences(t.texts_to_sequences([sentence]), maxlen=max_length, padding='post')\n",
    "    return np.argmax(model.predict(sequence, verbose = 0)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8vHx_A9_x4dm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.decode()111111\n",
      "2222222\n",
      "3333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'16'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(classify_sentence(\"data.decode()\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtfcXc8jHaQK"
   },
   "outputs": [],
   "source": [
    "ip = '192.168.1.107'\n",
    "port = 60200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "colab_type": "code",
    "id": "Uqgxi1zADdhO",
    "outputId": "6bbddc35-1e05-4876-c183-ea50716b576d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client connected\n",
      "open facebook newsfeedbefore classification\n",
      "open facebook newsfeed111111\n",
      "2222222\n",
      "3333333\n",
      "1\n",
      "after classification\n",
      "after sending\n",
      "Client connected\n",
      "find me a hospitalbefore classification\n",
      "find me a hospital111111\n",
      "2222222\n",
      "3333333\n",
      "6\n",
      "after classification\n",
      "after sending\n",
      "Client connected\n",
      "find me a hospitalbefore classification\n",
      "find me a hospital111111\n",
      "2222222\n",
      "3333333\n",
      "6\n",
      "after classification\n",
      "after sending\n",
      "Client connected\n",
      "did you see the hospitalbefore classification\n",
      "did you see the hospital111111\n",
      "2222222\n",
      "3333333\n",
      "6\n",
      "after classification\n",
      "after sending\n",
      "Client connected\n",
      "the sky is bluebefore classification\n",
      "the sky is blue111111\n",
      "2222222\n",
      "3333333\n",
      "16\n",
      "after classification\n",
      "after sending\n",
      "Client connected\n",
      "what is wrong with facebookbefore classification\n",
      "what is wrong with facebook111111\n",
      "2222222\n",
      "3333333\n",
      "16\n",
      "after classification\n",
      "after sending\n",
      "Client connected\n",
      "open Facebook timelinebefore classification\n",
      "open Facebook timeline111111\n",
      "2222222\n",
      "3333333\n",
      "1\n",
      "after classification\n",
      "after sending\n",
      "Client connected\n",
      "open Facebook timelinebefore classification\n",
      "open Facebook timeline111111\n",
      "2222222\n",
      "3333333\n",
      "1\n",
      "after classification\n",
      "after sending\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import threading\n",
    "\n",
    "class ThreadedServer(object):\n",
    "    def __init__(self, host, port):\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n",
    "        self.sock.bind((self.host, self.port))\n",
    "\n",
    "    def listen(self):\n",
    "        self.sock.listen(5)\n",
    "        while True:\n",
    "            client, address = self.sock.accept()\n",
    "            client.settimeout(60)\n",
    "            threading.Thread(target = self.listenToClient,args = (client,address)).start()\n",
    "\n",
    "    def listenToClient(self, client, address):\n",
    "        size = 1024\n",
    "        try:\n",
    "            data = client.recv(size)\n",
    "            if data:\n",
    "                print('Client connected')\n",
    "                print(data.decode()+\"before classification\")\n",
    "                response = str(classify_sentence(data.decode('utf-8'))) + '\\n'\n",
    "                print(response+\"after classification\")\n",
    "                client.sendall(response.encode('utf-8'))\n",
    "                print(\"after sending\")\n",
    "            else:\n",
    "                raise error('Client disconnected')\n",
    "        except:\n",
    "            client.close()\n",
    "            return False\n",
    "\n",
    "ThreadedServer(ip,port).listen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 962
    },
    "colab_type": "code",
    "id": "SrO6AALfIMnQ",
    "outputId": "e73b0609-532b-4b36-ad41-afd22b87f1fb"
   },
   "outputs": [],
   "source": [
    "classify_sentence(\"please open facebook newsfeed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task specific model",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
